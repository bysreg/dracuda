<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>DRacuda</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">DRacuda</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/bysreg/pcap_cmu_a5" class="btn">View on GitHub</a>
    </section>

    <section class="main-content">
      <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors</h3>

<p>Muhammad Hilman Beyri (mbeyri), Zixu Ding (zixud)</p>


<h3><a href="Checkpoint.pdf">Checkpoint Report</a></h3>

<h3>Summary</h3>

<p>We have developed a cloud-based CPU (SIMD)/GPU hybrid interactive raytracing demo, using an adaptive load-balancing algorithm which partitions work among nodes without knowing their computing power in advance.</p>

<h3>Achievements</h3>

<p>We started with hand-crafting a single-threaded pool table raytracing demo, and parallelized it with CUDA and CPU multi-threaded SIMD. The CUDA version achieves a MEASURING speedup, and the SIMD version has a MEASURING speedup. However, as the speedups on the same node are different, and the ratio of GPU/CPU computing power can also differ across nodes, we decided to implement a general heterogeneous load-balancing algorithm, which estimates a computing device's overall response time as a function of workload: y = f(x). Using different functions to estimate results in different load-balancing algorithms. We will give details of different algorithms we have tried in the following section.

<h3>
<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Load Balancer</h3>

<p>We created several load balancer algorithm.</p>

<ul>
<li>
<h4>Equal Division</h4>
<p>
In the beginning of the program, for a certain number of frame, dracuda will divide the workload equally to all nodes. This is because dracuda doesn't yet know anything about the connected nodes.
</p>
</li>

<li>
<h4>Naive Division</h4>
<p>
This is our first stab of implementing load balancer. We end up not using this. This algorithm will simply give bigger workload to node with smaller response time, which we know from the previous frame. This algorithm is prone to sudden change of node's response time. 
</p>
</li>

<li>
<h4>AB Division</h4>
<p>
We realize we can't just rely on the previous frame's information. We collect for each slave, their average network latency and their average rendering factor. Rendering factor is value we got from dividing rendering latency (the slaves send the rendering latency info to master) with the workload. So bigger rendering factor means slower compute capability.</p>

<p>
The slave's response time could be computed with : y = A * Bx. With A is the slave's average network latency (we assume it is not influenced by the workload), B is the slave's average rendering factor, and x is the workload. The goal of the algorithm is to find the same y for all slaves by varying the x for each slaves. The algorithm runs with O(n) time.</p>
<p>

<p>
For monday presentation, we will create a better grapth to illustrate the data, but for now, we have these data : </p> 

<p>Machines : </p>

	<ul>
	<li>
	ghc41 : NVIDIA GTX 780 GPU
	</li>
	<li>
	ghc42, ghc43, ghc32, ghc33 : NVIDIA GTX 670 GPU
	</li>
	</ul>


<p>2 Slaves, ghc41 & ghc42 (NVIDIA GTX) : </p>

	<ul>
		<li>
			Load Balancing Off (Equal Division): 
			<p>
			<b>Slave-0</b> </br>
			Response time:0.0235545 </br>
			Rendering latency: 0.0133358</br>
			Average network latency:0.0121292</br>
			Average rendering factor:4.63063e-05</br>

			<b>Slave-1</b> </br>
			Response time:0.0330588 </br>
			Rendering latency: 0.0198509</br>
			Average network latency:0.0131452 </br>
			Average rendering factor:6.59128e-05</br>
			</p>
		</li>
		<li>
			AB division : 
			<p>
			<b>Slave-0</b> </br>
			Response time:0.0332405 </br>
			Rendering latency: 0.0166288</br>
			Average network latency:0.0127753</br>
			Average rendering factor:4.68121e-05</br>

			<b>Slave-1</b> </br>
			Response time:0.0302952 </br>
			Rendering latency: 0.0164119</br>
			Average network latency:0.0127797</br>
			Average rendering factor:6.67132e-05</br>
			</p>
		</li>
	</ul>

	

</p>

</li>

</ul>

<h3>Background</h3>
<p>In computer graphics, ray tracing is a technique for generating an image by tracing the path of light through pixels in an image plane and simulating the effects of its encounters with virtual objects. As such, ray tracing is able to simulate necessary effects to create photorealistic images. However, a high-quality ray tracing can take very long time to render, and is not suitable for real-time applications.
</p>
<p>Essential operations in ray tracing, such as intersection tests, transformations, vector math and shading are all data-parallel operations, and therefore are SIMD friendly. Making use of SIMD processors like GPU or CPU SIMD instructions can immensely improve the speed of raytracing.</p>

<p>Many computers nowadays have both CPU and GPU installed. However, most of the time they are idle or poorly utilized. To extract maximum performance from a node, using both the CPU and GPU on the same node is definitely better than using either of them.</p>

<p>With the advent of cloud computing, it is possible to access massive computing resources without actually purchasing them. Even GPU computing instances have become available in the past few years. Therefore, with enough cloud instances, real-time rendering is possible without sacrificing the quality. </p>

<p>Load balancing across heterogeneous nodes can be difficult. That is largely due to the differences of network latency and GPU performance among nodes. In order to balance the overall latency, which we estimate as network latency + work load * rendering time per unit work load, we will gather the rendering time and latency from worker nodes, and use an adaptive linear regression algorithm to predict the network latency and unit rendering time of next frame, and then assign the work load of each node accordingly.</p>

<p>The architecture of this project is simple. Worker nodes are responsible for rendering. They take scene data and the work assignment information (like from Row A - Row B) as input, and send back the rendered portion of the image (compressed). The local client divides the screen into tiles, sends the scene data and work allocation to worker nodes, and collects all the image parts from worker nodes and display the frames. It also adjusts the work assignment each frame using the adaptive algorithm we mentioned above.</p>

<h3>

<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Challenge</h3>
<p>
Performance
<ul>
<li>Network Latency. The latency from Pittsburgh to Amazon US East server is 23 ms. A round-trip would be 46 ms. For a player to not experience lag, the latency has to be below 100 ms, so that restricts the rendering time under 50 ms. Besides, we are aiming for a frame rate of at least 30 FPS, so our goal is to limit the rendering time of each frame to below 33 ms, to ensure the throughput is enough for the 30 FPS experience.</li>
<li>Load Balancing Algorithm. Different compute nodes have different rendering performance and network latency. Therefore it is challenging to balance the overall latency of all nodes. We will continuously gather analytics data from nodes to adaptively balance the latency.</li>
<li>Efficient GPU and CPU-SIMD ray tracing implementation. Even though ray tracing is highly parallelizable, there are branch divergences in intersection tests, refraction / reflections, which can cause huge performance slowdown if not handled properly.</li>
</ul>
Graphics
<ul>
<li>Photorealistic Rendering. To make the rendering as pretty as possible, some effects like caustics, subsurface scattering, diffuse reflection are both difficult to simulate and computationally intensive.</li>

</ul>
</p>

<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><h3>Resources</h3>
<p>
We have taken 15-662 Computer Graphics and developed a ray tracer on CPU. We will write a single-threaded hardcoded version of the pool scene, and parallelize it using both CUDA and multi-threaded SIMD. During the development, we will use GHC clusters with GPU to test. We will also make sure it works on Amazon EC2, and will run the demo game on it.
</p>

<h3>Goals and Deliverables</h3>
<p>
	We plan to achieve:
	<ul>
	<li>Distributed parallel ray tracing using CUDA</li>
	<li>Load balancer algorithm that adapts to the network latency and worker nodes' computation time</li>
	<li>API to create distributed ray tracing application</li>
	<li>A game as an example of one of the ray tracing application</li>
	<li>Analysis of the performance of the ray tracer. We hope to achieve real time performance with high quality images</li>
	</ul>
	
	We hope to achieve:
	<ul>
	<li>Particle simulation using material point method</li>
	<li>Subsurface scattering</li>
	<li>CPU and GPU Hybrid parallelization</li>
	</ul>
</p>

<h3>Platform Choice</h3>
<p>
	We are using CUDA and C++ as our main programming language. The client will be a thin client application using SDL and OpenGL. The client will communicate with other worker nodes using a network protocol that we are going to design. We chose to assume the worker nodes have GPUs that support CUDA.
</p>

<h3>Schedule</h3>
<p>
	<ul>
		<li>April 10: Implemented working GPU ray tracer with basic intersection tests and lighting</li>
		<li>April 13: Integrated external physics simulation code for demo</li>
		<li>April 18: Created pool scene and implemented appropriate lighting and materials</li>
		<li>April 23: Design and implementation of the communication protocol between client and server (Hilman)</li>
		<li>April 23: Ray tracer optimization and develop the demo scene (Zixu) </li>
		<li>April 27: Load balancing algorithm design and tuning (Zixu and Hilman)</li>
		<li>May 1: Implement a lossless compression algorithm to reduce the network and IO overhead for transferring the image (Zixu)</li>
		<li>May 1: Deployment on Amazon EC2 GPU instances, and heterogeneous GHC machines to evaluate performance (Hilman)</li>
		<li>May 5: Final parameter tuning according to testing result, write final report and presentation</li>
		<li>Monday, May 9: Presentation</li>
	</ul>
</p>


      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
